{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Speed Check\n",
    "### Complete # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Save as GIF\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m frames:\n\u001b[1;32m---> 30\u001b[0m     \u001b[43mframes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mGIF_OUTPUT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mappend_images\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGIF saved at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mGIF_OUTPUT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\CV_ENV\\lib\\site-packages\\PIL\\Image.py:2568\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2565\u001b[0m     fp \u001b[38;5;241m=\u001b[39m cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n\u001b[0;32m   2567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2568\u001b[0m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2569\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   2570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "File \u001b[1;32m~\\CV_ENV\\lib\\site-packages\\PIL\\GifImagePlugin.py:737\u001b[0m, in \u001b[0;36m_save_all\u001b[1;34m(im, fp, filename)\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_save_all\u001b[39m(im: Image\u001b[38;5;241m.\u001b[39mImage, fp: IO[\u001b[38;5;28mbytes\u001b[39m], filename: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 737\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\CV_ENV\\lib\\site-packages\\PIL\\GifImagePlugin.py:750\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, filename, save_all)\u001b[0m\n\u001b[0;32m    747\u001b[0m     palette \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    748\u001b[0m     im\u001b[38;5;241m.\u001b[39mencoderinfo\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_all \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43m_write_multiple_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    751\u001b[0m     _write_single_frame(im, fp, palette)\n\u001b[0;32m    753\u001b[0m fp\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# end of file\u001b[39;00m\n",
      "File \u001b[1;32m~\\CV_ENV\\lib\\site-packages\\PIL\\GifImagePlugin.py:629\u001b[0m, in \u001b[0;36m_write_multiple_frames\u001b[1;34m(im, fp, palette)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m imSequence \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain([im], im\u001b[38;5;241m.\u001b[39mencoderinfo\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend_images\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])):\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m im_frame \u001b[38;5;129;01min\u001b[39;00m ImageSequence\u001b[38;5;241m.\u001b[39mIterator(imSequence):\n\u001b[0;32m    628\u001b[0m         \u001b[38;5;66;03m# a copy is required here since seek can still mutate the image\u001b[39;00m\n\u001b[1;32m--> 629\u001b[0m         im_frame \u001b[38;5;241m=\u001b[39m \u001b[43m_normalize_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim_frame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m frame_count \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    631\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m im_frame\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32m~\\CV_ENV\\lib\\site-packages\\PIL\\GifImagePlugin.py:498\u001b[0m, in \u001b[0;36m_normalize_mode\u001b[1;34m(im)\u001b[0m\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m im\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mgetmodebase(im\u001b[38;5;241m.\u001b[39mmode) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 498\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPalette\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mADAPTIVE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mpalette\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGBA\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rgba \u001b[38;5;129;01min\u001b[39;00m im\u001b[38;5;241m.\u001b[39mpalette\u001b[38;5;241m.\u001b[39mcolors:\n",
      "File \u001b[1;32m~\\CV_ENV\\lib\\site-packages\\PIL\\Image.py:1104\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m   1101\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m palette \u001b[38;5;241m==\u001b[39m Palette\u001b[38;5;241m.\u001b[39mADAPTIVE:\n\u001b[1;32m-> 1104\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m     new_im \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(im)\n\u001b[0;32m   1106\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImagePalette\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Paths\n",
    "VIDEO_ADDRESS = os.path.join(\"videos\", \"cars.mp4\")\n",
    "GIF_OUTPUT = os.path.join(\"output\", \"video_rgb.gif\")\n",
    "\n",
    "# Load the video\n",
    "video = cv2.VideoCapture(VIDEO_ADDRESS)\n",
    "if not video.isOpened():\n",
    "    raise IOError(f\"Failed to open video file at {VIDEO_ADDRESS}\")\n",
    "\n",
    "frames = []\n",
    "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "frame_skip = 5  # Number of frames to skip (adjust for fewer frames in GIF)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    if video.get(cv2.CAP_PROP_POS_FRAMES) % frame_skip != 0:\n",
    "        continue  # Skip frames that are not multiples of frame_skip\n",
    "\n",
    "    # Resize frame and ensure RGB format\n",
    "    frame = cv2.resize(frame, (640, 360))  # Reduce size for GIF\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "    frames.append(Image.fromarray(frame))\n",
    "\n",
    "video.release()\n",
    "\n",
    "# Save as GIF\n",
    "if frames:\n",
    "    duration = (1000 / fps) * frame_skip  # Adjust duration based on frame_skip\n",
    "    frames[0].save(\n",
    "        GIF_OUTPUT,\n",
    "        save_all=True,\n",
    "        append_images=frames[1:],\n",
    "        optimize=False,\n",
    "        duration=duration,\n",
    "        loop=0\n",
    "    )\n",
    "    print(f\"GIF saved at {GIF_OUTPUT}\")\n",
    "else:\n",
    "    print(\"No frames to save.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 0: Detected 2 cars.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unsupported image type, must be 8bit gray or RGB image.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 79\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m matchCarID \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     tracker \u001b[38;5;241m=\u001b[39m dlib\u001b[38;5;241m.\u001b[39mcorrelation_tracker()\n\u001b[1;32m---> 79\u001b[0m     \u001b[43mtracker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_track\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrectangle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     carTracker[currentCarID] \u001b[38;5;241m=\u001b[39m tracker\n\u001b[0;32m     81\u001b[0m     carLocation1[currentCarID] \u001b[38;5;241m=\u001b[39m [x, y, w, h]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unsupported image type, must be 8bit gray or RGB image."
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "GIF_INPUT = os.path.join(\"output\", \"video.gif\")\n",
    "TRACKED_VIDEO_OUTPUT = os.path.join(\"output\", \"tracked_video.mp4\")\n",
    "MODEL_ADDRESS = os.path.join(\"models\", \"myhaar.xml\")\n",
    "\n",
    "# Load Haar Cascade\n",
    "carCascade = cv2.CascadeClassifier(MODEL_ADDRESS)\n",
    "if carCascade.empty():\n",
    "    raise IOError(f\"Failed to load model at {MODEL_ADDRESS}\")\n",
    "\n",
    "# Load the GIF\n",
    "gif = Image.open(GIF_INPUT)\n",
    "frames = []\n",
    "while True:\n",
    "    try:\n",
    "        frame = gif.copy().convert(\"RGB\")\n",
    "        frame = np.array(frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        frames.append(frame)\n",
    "        gif.seek(gif.tell() + 1)\n",
    "    except EOFError:\n",
    "        break\n",
    "\n",
    "# Constants\n",
    "WIDTH, HEIGHT = frames[0].shape[1], frames[0].shape[0]\n",
    "rectangleColor = (0, 255, 0)\n",
    "carTracker = {}\n",
    "carLocation1 = {}\n",
    "carLocation2 = {}\n",
    "currentCarID = 0\n",
    "speed = [None] * 1000\n",
    "\n",
    "# Video writer\n",
    "out = cv2.VideoWriter(\n",
    "    TRACKED_VIDEO_OUTPUT, cv2.VideoWriter_fourcc(*\"mp4v\"), 10, (WIDTH, HEIGHT)\n",
    ")\n",
    "\n",
    "def estimateSpeed(location1, location2):\n",
    "    d_pixels = math.sqrt(\n",
    "        math.pow(location2[0] - location1[0], 2) +\n",
    "        math.pow(location2[1] - location1[1], 2)\n",
    "    )\n",
    "    ppm = 8.8  # Pixels per meter\n",
    "    d_meters = d_pixels / ppm\n",
    "    fps = 10  # Frames per second\n",
    "    speed = d_meters * fps * 3.6  # Speed in km/hr\n",
    "    return speed\n",
    "\n",
    "# Process each frame\n",
    "for frame_idx, frame in enumerate(frames):\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result_frame = frame.copy()\n",
    "\n",
    "    # Detect cars every 10 frames\n",
    "    if frame_idx % 10 == 0:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        cars = carCascade.detectMultiScale(\n",
    "            gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30)\n",
    "        )\n",
    "        print(f\"Frame {frame_idx}: Detected {len(cars)} cars.\")\n",
    "\n",
    "        for (x, y, w, h) in cars:\n",
    "            matchCarID = None\n",
    "            for carID in carTracker.keys():\n",
    "                trackedPosition = carTracker[carID].get_position()\n",
    "                t_x = int(trackedPosition.left())\n",
    "                t_y = int(trackedPosition.top())\n",
    "                t_w = int(trackedPosition.width())\n",
    "                t_h = int(trackedPosition.height())\n",
    "\n",
    "                if (\n",
    "                    (t_x <= x + w // 2 <= t_x + t_w)\n",
    "                    and (t_y <= y + h // 2 <= t_y + t_h)\n",
    "                ):\n",
    "                    matchCarID = carID\n",
    "\n",
    "            if matchCarID is None:\n",
    "                tracker = dlib.correlation_tracker()\n",
    "                tracker.start_track(rgb_frame, dlib.rectangle(x, y, x + w, y + h))\n",
    "                carTracker[currentCarID] = tracker\n",
    "                carLocation1[currentCarID] = [x, y, w, h]\n",
    "                currentCarID += 1\n",
    "\n",
    "    # Update trackers\n",
    "    for carID in list(carTracker.keys()):\n",
    "        trackingQuality = carTracker[carID].update(rgb_frame)\n",
    "        if trackingQuality < 7:\n",
    "            print(f\"Removing carID {carID} due to poor tracking quality.\")\n",
    "            del carTracker[carID]\n",
    "            del carLocation1[carID]\n",
    "            continue\n",
    "\n",
    "        trackedPosition = carTracker[carID].get_position()\n",
    "        t_x = int(trackedPosition.left())\n",
    "        t_y = int(trackedPosition.top())\n",
    "        t_w = int(trackedPosition.width())\n",
    "        t_h = int(trackedPosition.height())\n",
    "\n",
    "        carLocation2[carID] = [t_x, t_y, t_w, t_h]\n",
    "        cv2.rectangle(result_frame, (t_x, t_y), (t_x + t_w, t_y + t_h), rectangleColor, 2)\n",
    "\n",
    "        if carID in carLocation1:\n",
    "            [x1, y1, w1, h1] = carLocation1[carID]\n",
    "            [x2, y2, w2, h2] = carLocation2[carID]\n",
    "            carLocation1[carID] = [x2, y2, w2, h2]\n",
    "\n",
    "            if [x1, y1, w1, h1] != [x2, y2, w2, h2]:\n",
    "                if speed[carID] is None and 275 <= y1 <= 285:\n",
    "                    speed[carID] = estimateSpeed([x1, y1], [x2, y2])\n",
    "                if speed[carID] is not None:\n",
    "                    cv2.putText(\n",
    "                        result_frame,\n",
    "                        f\"{int(speed[carID])} km/hr\",\n",
    "                        (t_x, t_y - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.5,\n",
    "                        (255, 255, 255),\n",
    "                        1,\n",
    "                    )\n",
    "\n",
    "    # Write frame to video\n",
    "    out.write(result_frame)\n",
    "\n",
    "# Release resources\n",
    "out.release()\n",
    "print(f\"Tracked video saved at {TRACKED_VIDEO_OUTPUT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
